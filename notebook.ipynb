{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "98iXpM6Hv_uA",
        "oL4Is76diAkK",
        "FgujKy-3iF0p",
        "k50yLlhdvijr",
        "vYk9wK8pvnYh",
        "Og5YkJ7wvrel",
        "Oagb-5H-veXO",
        "vG_wYWGIvxxq",
        "41CGLLSsv1Pd"
      ]
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "#Import statements and global variables assignement"
      ],
      "metadata": {
        "id": "98iXpM6Hv_uA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import cv2\n",
        "import numpy as np\n",
        "import random,os,subprocess\n",
        "from moviepy.editor import VideoFileClip, concatenate_videoclips"
      ],
      "metadata": {
        "id": "AU_UYmXYhzxr"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ideas_file='file.txt'\n",
        "with open(ideas_file,'r') as file:\n",
        "  ideas=file.readlines()\n",
        "c=0\n",
        "for i in range(len(ideas)):\n",
        "  ideas[i]=ideas[i][0:len(ideas[i])-1]\n",
        "  c+=len(ideas[i])\n",
        "print(ideas)\n",
        "print(c)"
      ],
      "metadata": {
        "id": "iQo5flaNV2JN",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c180cc69-5f86-44e4-ac5f-13647576f044"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['Fondée en 1933,', 'contenant 260 milliards de barils', 'devant les autres société']\n",
            "73\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "image_paths = [\"image1.jpeg\", \"image2.jpg\", \"image3.jpg\", \"image4.jpeg\"]\n",
        "fps=24\n",
        "total_duration = 0.5*c+0.5\n",
        "output_path = \"video.mp4\"\n",
        "final_video=\"final.mp4\"\n",
        "print(total_duration,' in seconds')\n",
        "print(total_duration/60,' in minutes')\n",
        "\n",
        "line_percentage=[0 for i in ideas]\n",
        "for i in range(len(ideas)) :\n",
        "  line_percentage[i]=(total_duration*len(ideas[i])/c)+0.5\n",
        "\n",
        "print(line_percentage)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "D7qVOv1tYpq3",
        "outputId": "c1ff4df8-4fab-4e48-e809-12de7abe0905"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "37.0  in seconds\n",
            "0.6166666666666667  in minutes\n",
            "[8.102739726027398, 17.226027397260275, 13.17123287671233]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Animations"
      ],
      "metadata": {
        "id": "oL4Is76diAkK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def zoom_in(image_path, output_path, duration=3, fps=30, max_scale=1.15):\n",
        "    # Load the image\n",
        "    image = cv2.imread(image_path)\n",
        "    height, width, _ = image.shape\n",
        "\n",
        "    # Define the codec and create VideoWriter object\n",
        "    fourcc = cv2.VideoWriter_fourcc(*'mp4v')\n",
        "    out = cv2.VideoWriter(output_path, fourcc, fps, (width, height))\n",
        "\n",
        "    # Calculate the scale increment per frame\n",
        "    scale_increment = (max_scale - 1.0) / (duration * fps)\n",
        "\n",
        "    # Calculate the center of the image\n",
        "    center_x, center_y = width // 2, height // 2\n",
        "\n",
        "    # Create the zoom-out frames\n",
        "    current_scale = 1.0\n",
        "    for i in range(int(duration * fps)):\n",
        "        # Calculate the current scale for this frame\n",
        "        current_scale += scale_increment\n",
        "\n",
        "        # Calculate the translation to keep the center fixed\n",
        "        translation_x = center_x * (1 - current_scale)\n",
        "        translation_y = center_y * (1 - current_scale)\n",
        "\n",
        "        # Create a scaling and translation matrix to zoom out the image from the center\n",
        "        transformation_matrix = np.float32([[current_scale, 0, translation_x], [0, current_scale, translation_y]])\n",
        "\n",
        "        # Apply the transformation to the image\n",
        "        zoomed_in_image = cv2.warpAffine(image, transformation_matrix, (width, height))\n",
        "\n",
        "        # Write the frame to the video\n",
        "        out.write(zoomed_in_image)\n",
        "\n",
        "    # Release the video writer\n",
        "    out.release()\n",
        "\n",
        "\n",
        "def zoom_out(image_path, output_path, duration=3, fps=30, max_scale=1.15):\n",
        "    # Load the image\n",
        "    image = cv2.imread(image_path)\n",
        "    height, width, _ = image.shape\n",
        "\n",
        "    # Define the codec and create VideoWriter object\n",
        "    fourcc = cv2.VideoWriter_fourcc(*'mp4v')\n",
        "    out = cv2.VideoWriter(output_path, fourcc, fps, (width, height))\n",
        "\n",
        "    # Calculate the scale decrement per frame\n",
        "    scale_decrement = (max_scale - 1.0) / (duration * fps)\n",
        "\n",
        "    # Calculate the center of the image\n",
        "    center_x, center_y = width // 2, height // 2\n",
        "\n",
        "    # Create the zoom-in frames\n",
        "    current_scale = max_scale\n",
        "    for i in range(int(duration * fps)):\n",
        "        # Calculate the current scale for this frame\n",
        "        current_scale -= scale_decrement\n",
        "\n",
        "        # Calculate the translation to keep the center fixed\n",
        "        translation_x = center_x * (1 - current_scale)\n",
        "        translation_y = center_y * (1 - current_scale)\n",
        "\n",
        "        # Create a scaling and translation matrix to zoom in the image from the center\n",
        "        transformation_matrix = np.float32([[current_scale, 0, translation_x], [0, current_scale, translation_y]])\n",
        "\n",
        "        # Apply the transformation to the image\n",
        "        zoomed_out_image = cv2.warpAffine(image, transformation_matrix, (width, height))\n",
        "\n",
        "        # Write the frame to the video\n",
        "        out.write(zoomed_out_image)\n",
        "\n",
        "    # Release the video writer\n",
        "    out.release()\n",
        "\n",
        "def translate_left(image_path, output_path, duration=3, fps=30):\n",
        "    # Load the image\n",
        "    image = cv2.imread(image_path)\n",
        "    height, width, _ = image.shape\n",
        "\n",
        "    # Calculate the width of the visible portion (90% of the image width)\n",
        "    visible_width = int(width * 0.9)\n",
        "\n",
        "    # Define the codec and create VideoWriter object\n",
        "    fourcc = cv2.VideoWriter_fourcc(*'mp4v')\n",
        "    out = cv2.VideoWriter(output_path, fourcc, fps, (visible_width, height))\n",
        "\n",
        "    # Calculate the total translation distance for the entire duration\n",
        "    total_translation_distance = width - visible_width\n",
        "\n",
        "    # Calculate the translation distance per second\n",
        "    translation_per_second = total_translation_distance / duration\n",
        "\n",
        "    # Create the translated frames\n",
        "    for i in range(int(duration * fps)):\n",
        "        # Calculate the translation distance for this frame\n",
        "        translation_distance = int(i / fps * translation_per_second)\n",
        "\n",
        "        # Create a translation matrix to shift the image to the left\n",
        "        translation_matrix = np.float32([[1, 0, -translation_distance], [0, 1, 0]])\n",
        "\n",
        "        # Apply the translation to the image\n",
        "        translated_image = cv2.warpAffine(image, translation_matrix, (visible_width, height))\n",
        "\n",
        "        # Write the frame to the video\n",
        "        out.write(translated_image)\n",
        "\n",
        "    # Release everything if job is finished\n",
        "    out.release()\n",
        "\n",
        "\n",
        "def translate_right(image_path, output_path, duration=3, fps=30):\n",
        "    # Load the image\n",
        "    image = cv2.imread(image_path)\n",
        "    height, width, _ = image.shape\n",
        "\n",
        "    # Calculate the width of the visible portion (90% of the image width)\n",
        "    visible_width = int(width * 0.9)\n",
        "\n",
        "    # Define the codec and create VideoWriter object\n",
        "    fourcc = cv2.VideoWriter_fourcc(*'mp4v')\n",
        "    out = cv2.VideoWriter(output_path, fourcc, fps, (visible_width, height))\n",
        "\n",
        "    # Calculate the total translation distance for the entire duration\n",
        "    total_translation_distance = width - visible_width\n",
        "\n",
        "    # Calculate the translation distance per second\n",
        "    translation_per_second = total_translation_distance / duration\n",
        "\n",
        "    # Create the translated frames\n",
        "    frames = []\n",
        "    for i in range(int(duration * fps)):\n",
        "        # Calculate the translation distance for this frame\n",
        "        translation_distance = int(i / fps * translation_per_second)\n",
        "\n",
        "        # Create a translation matrix to shift the image to the left\n",
        "        translation_matrix = np.float32([[1, 0, -translation_distance], [0, 1, 0]])\n",
        "\n",
        "        # Apply the translation to the image\n",
        "        translated_image = cv2.warpAffine(image, translation_matrix, (visible_width, height))\n",
        "\n",
        "        # Append the frame to the frames list\n",
        "        frames.append(translated_image)\n",
        "\n",
        "    # Append the frames in reverse order to the output video to get the inverse effect\n",
        "    for frame in reversed(frames):\n",
        "        out.write(frame)\n",
        "\n",
        "    # Release everything if job is finished\n",
        "    out.release()"
      ],
      "metadata": {
        "id": "8HIMOxpPh3mX"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#video creation phase 1:"
      ],
      "metadata": {
        "id": "FgujKy-3iF0p"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Function to concatenate video clips into a single video using moviepy\n",
        "def concatenate_videos(video_paths, output_path, target_resolution=(1280,720)):\n",
        "    # Create VideoFileClip objects for each video and resize to the target resolution\n",
        "    video_clips = [VideoFileClip(video_path).resize(target_resolution) for video_path in video_paths]\n",
        "\n",
        "    # Concatenate the video clips\n",
        "    final_clip = concatenate_videoclips(video_clips, method=\"compose\")\n",
        "\n",
        "    # Write the final video to the output path\n",
        "    final_clip.write_videofile(output_path, codec=\"libx264\", audio_codec=\"aac\")\n",
        "\n",
        "    # Close the video clips\n",
        "    for video_clip in video_clips:\n",
        "        video_clip.close()\n",
        "\n",
        "# Function to create a video with transitions between images\n",
        "def create_transition_video(image_paths, output_path, total_duration, fps=30, animations=None):\n",
        "    if not animations:\n",
        "        animations = [zoom_in, translate_left, zoom_out, translate_right]\n",
        "\n",
        "    # Create temporary video animations for each image\n",
        "    video_paths = []\n",
        "    i=0\n",
        "    for image_path in image_paths:\n",
        "      video_path=f'temp_video_for_image_n_{i}.mp4'\n",
        "      create_image_animation=random.choice(animations)\n",
        "      create_image_animation(image_path, video_path, total_duration / len(image_paths), fps)\n",
        "      video_paths.append(video_path)\n",
        "      i+=1\n",
        "\n",
        "    # Concatenate the temporary videos to create the final video\n",
        "    concatenate_videos(video_paths, output_path)\n",
        "\n",
        "    # Remove temporary video files\n",
        "    for video_path in video_paths:\n",
        "        os.remove(video_path)"
      ],
      "metadata": {
        "id": "7z8ElGtFiQmY"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "create_transition_video(image_paths, output_path, total_duration, fps)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qv1v1ruqiRgQ",
        "outputId": "16b3d6ae-810b-4098-96c4-09574195844e"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Moviepy - Building video video.mp4.\n",
            "Moviepy - Writing video video.mp4\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Moviepy - Done !\n",
            "Moviepy - video ready video.mp4\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Video creation phase 2:"
      ],
      "metadata": {
        "id": "iiRgFXqTiYMn"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##CV2"
      ],
      "metadata": {
        "id": "k50yLlhdvijr"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Option 1"
      ],
      "metadata": {
        "id": "vYk9wK8pvnYh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import cv2\n",
        "import numpy as np\n",
        "\n",
        "# Load the video file\n",
        "cap = cv2.VideoCapture(output_path)\n",
        "frame_count = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
        "\n",
        "\n",
        "# Calculate the start and end frames for each subtitle\n",
        "start_frames = [int(sum(line_percentage[:i]) * fps) for i in range(len(line_percentage))]\n",
        "end_frames = [int(sum(line_percentage[:i+1]) * fps) for i in range(len(line_percentage))]\n",
        "\n",
        "# Set up the video writer\n",
        "fourcc = cv2.VideoWriter_fourcc(*'mp4v')\n",
        "out = cv2.VideoWriter(final_video, fourcc, fps, (int(cap.get(3)), int(cap.get(4))))\n",
        "\n",
        "# Add the subtitles to the video\n",
        "frame_num = 0\n",
        "while cap.isOpened():\n",
        "    ret, frame = cap.read()\n",
        "    if not ret:\n",
        "        break\n",
        "\n",
        "    # Check if we need to add a subtitle to this frame\n",
        "    for i, (start, end) in enumerate(zip(start_frames, end_frames)):\n",
        "        if start <= frame_num < end:\n",
        "            # Add the subtitle to the frame\n",
        "            font = cv2.FONT_HERSHEY_SIMPLEX\n",
        "            text = ideas[i]\n",
        "            textsize = cv2.getTextSize(text, font, 1, 2)[0]\n",
        "            textX = (frame.shape[1] - textsize[0]) // 2\n",
        "            textY = frame.shape[0] - 50\n",
        "            cv2.putText(frame, text, (textX, textY), font, 1, (255, 255, 255), 2)\n",
        "\n",
        "    # Write the frame to the output video\n",
        "    out.write(frame)\n",
        "    frame_num += 1\n",
        "\n",
        "# Release resources\n",
        "cap.release()\n",
        "out.release()\n"
      ],
      "metadata": {
        "id": "1G9Gth7QhYyG"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Option 2"
      ],
      "metadata": {
        "id": "Og5YkJ7wvrel"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import cv2\n",
        "import numpy as np\n",
        "import random\n",
        "\n",
        "# Load the video file\n",
        "cap = cv2.VideoCapture(output_path)\n",
        "frame_count = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
        "\n",
        "# Calculate the start and end frames for each subtitle\n",
        "start_frames = [int(sum(line_percentage[:i]) * fps) for i in range(len(line_percentage))]\n",
        "end_frames = [int(sum(line_percentage[:i+1]) * fps) for i in range(len(line_percentage))]\n",
        "\n",
        "# Set up the video writer\n",
        "fourcc = cv2.VideoWriter_fourcc(*'mp4v')\n",
        "out = cv2.VideoWriter(final_video, fourcc, fps, (int(cap.get(3)), int(cap.get(4))))\n",
        "\n",
        "# Define the subtitle animations\n",
        "animations = ['left', 'right', 'top', 'bottom', 'fade']\n",
        "\n",
        "def apply_animation(frame, text, animation, progress):\n",
        "    font = cv2.FONT_HERSHEY_SIMPLEX\n",
        "    textsize = cv2.getTextSize(text, font, 1, 2)[0]\n",
        "    text_width, text_height = textsize\n",
        "    x_center = (frame.shape[1] - text_width) // 2\n",
        "    y_center = frame.shape[0] - 50\n",
        "\n",
        "    if animation == 'left':\n",
        "        x_pos = int(x_center * progress)\n",
        "        y_pos = y_center\n",
        "    elif animation == 'right':\n",
        "        x_pos = int(x_center + (frame.shape[1] - x_center) * (1 - progress))\n",
        "        y_pos = y_center\n",
        "    elif animation == 'top':\n",
        "        x_pos = x_center\n",
        "        y_pos = int(y_center * progress)\n",
        "    elif animation == 'bottom':\n",
        "        x_pos = x_center\n",
        "        y_pos = int(y_center + (frame.shape[0] - y_center) * (1 - progress))\n",
        "    elif animation == 'fade':\n",
        "        x_pos = x_center\n",
        "        y_pos = y_center\n",
        "\n",
        "    # Add a black background to the subtitle\n",
        "    bg_thickness = 3\n",
        "    bg_color = (0, 0, 0)\n",
        "    top_left = (x_pos - bg_thickness, y_pos + bg_thickness)\n",
        "    bottom_right = (x_pos + text_width + bg_thickness, y_pos - text_height - bg_thickness)\n",
        "    cv2.rectangle(frame, top_left, bottom_right, bg_color, -1)\n",
        "\n",
        "    # Add the subtitle to the frame\n",
        "    font_color = (241, 213, 0)\n",
        "    cv2.putText(frame, text, (x_pos, y_pos), font, 1, font_color, 2)\n",
        "\n",
        "    # Apply the fade animation if necessary\n",
        "    if animation == 'fade':\n",
        "        alpha = progress\n",
        "        beta = 1 - alpha\n",
        "        frame[:] = cv2.addWeighted(frame, alpha, np.zeros_like(frame), beta, 0)\n",
        "\n",
        "# Add the subtitles to the video\n",
        "frame_num = 0\n",
        "while cap.isOpened():\n",
        "    ret, frame = cap.read()\n",
        "    if not ret:\n",
        "        break\n",
        "\n",
        "    # Check if we need to add a subtitle to this frame\n",
        "    for i, (start, end) in enumerate(zip(start_frames, end_frames)):\n",
        "        if start <= frame_num < end:\n",
        "            # Calculate the progress of the animation\n",
        "            progress = (frame_num - start) / (end - start)\n",
        "\n",
        "            # Apply a random animation to the subtitle\n",
        "            animation = random.choice(animations)\n",
        "            apply_animation(frame, ideas[i], animation, progress)\n",
        "\n",
        "    # Write the frame to the output video\n",
        "    out.write(frame)\n",
        "    frame_num += 1\n",
        "\n",
        "# Release resources\n",
        "cap.release()\n",
        "out.release()\n"
      ],
      "metadata": {
        "id": "zpFCdwjKmP7A"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Moviepy"
      ],
      "metadata": {
        "id": "Oagb-5H-veXO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Option 1"
      ],
      "metadata": {
        "id": "vG_wYWGIvxxq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from moviepy.editor import VideoFileClip, TextClip\n",
        "from moviepy.video.tools.subtitles import SubtitlesClip\n",
        "\n",
        "# Load the video file\n",
        "video_clip = VideoFileClip(output_path)\n",
        "\n",
        "# Create subtitle clips\n",
        "subtitles = []\n",
        "start_time = 0\n",
        "for idea, duration in zip(ideas, line_percentage):\n",
        "    end_time = start_time + duration\n",
        "    subtitle = TextClip(idea, fontsize=24, color='white', bg_color='black', size=video_clip.size)\n",
        "    subtitles.append(((start_time, end_time), subtitle))\n",
        "    start_time = end_time\n",
        "\n",
        "# Create the subtitle composition\n",
        "subtitles_composition = SubtitlesClip(subtitles)\n",
        "\n",
        "# Overlay subtitles on the video\n",
        "video_with_subtitles = CompositeVideoClip([video_clip, subtitles_composition.set_duration(video_clip.duration)])\n",
        "\n",
        "# Export the final video\n",
        "video_with_subtitles.write_videofile(final_video, codec='libx264')\n"
      ],
      "metadata": {
        "id": "Z5AWgm90kZ3E",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 564
        },
        "outputId": "29b9c091-7a1d-4c05-c2af-a86649f5afb0"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "error",
          "ename": "OSError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/moviepy/video/VideoClip.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, txt, filename, size, color, bg_color, fontsize, font, stroke_color, stroke_width, method, kerning, align, interline, tempfilename, temptxt, transparent, remove_temp, print_cmd)\u001b[0m\n\u001b[1;32m   1136\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1137\u001b[0;31m             \u001b[0msubprocess_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcmd\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogger\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1138\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mIOError\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mOSError\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/moviepy/tools.py\u001b[0m in \u001b[0;36msubprocess_call\u001b[0;34m(cmd, logger, errorprint)\u001b[0m\n\u001b[1;32m     45\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 46\u001b[0;31m     \u001b[0mproc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mPopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcmd\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mpopen_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     47\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.10/subprocess.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, args, bufsize, executable, stdin, stdout, stderr, preexec_fn, close_fds, shell, cwd, env, universal_newlines, startupinfo, creationflags, restore_signals, start_new_session, pass_fds, user, group, extra_groups, encoding, errors, text, umask, pipesize)\u001b[0m\n\u001b[1;32m    970\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 971\u001b[0;31m             self._execute_child(args, executable, preexec_fn, close_fds,\n\u001b[0m\u001b[1;32m    972\u001b[0m                                 \u001b[0mpass_fds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcwd\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0menv\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.10/subprocess.py\u001b[0m in \u001b[0;36m_execute_child\u001b[0;34m(self, args, executable, preexec_fn, close_fds, pass_fds, cwd, env, startupinfo, creationflags, shell, p2cread, p2cwrite, c2pread, c2pwrite, errread, errwrite, restore_signals, gid, gids, uid, umask, start_new_session)\u001b[0m\n\u001b[1;32m   1862\u001b[0m                         \u001b[0merr_msg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstrerror\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merrno_num\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1863\u001b[0;31m                     \u001b[0;32mraise\u001b[0m \u001b[0mchild_exception_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merrno_num\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merr_msg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merr_filename\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1864\u001b[0m                 \u001b[0;32mraise\u001b[0m \u001b[0mchild_exception_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merr_msg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'unset'",
            "\nDuring handling of the above exception, another exception occurred:\n",
            "\u001b[0;31mOSError\u001b[0m                                   Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-9-9fe144282424>\u001b[0m in \u001b[0;36m<cell line: 10>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0midea\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mduration\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mideas\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mline_percentage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m     \u001b[0mend_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstart_time\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mduration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m     \u001b[0msubtitle\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextClip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0midea\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfontsize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m24\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolor\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'white'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbg_color\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'black'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvideo_clip\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m     \u001b[0msubtitles\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstart_time\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mend_time\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msubtitle\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m     \u001b[0mstart_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mend_time\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/moviepy/video/VideoClip.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, txt, filename, size, color, bg_color, fontsize, font, stroke_color, stroke_width, method, kerning, align, interline, tempfilename, temptxt, transparent, remove_temp, print_cmd)\u001b[0m\n\u001b[1;32m   1144\u001b[0m                         \u001b[0;34m\"ImageMagick binary in file conf.py, or that the path \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1145\u001b[0m                         \"you specified is incorrect\"))\n\u001b[0;32m-> 1146\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mIOError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merror\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1147\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1148\u001b[0m         \u001b[0mImageClip\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtempfilename\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtransparent\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtransparent\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mOSError\u001b[0m: MoviePy Error: creation of None failed because of the following error:\n\n[Errno 2] No such file or directory: 'unset'.\n\n.This error can be due to the fact that ImageMagick is not installed on your computer, or (for Windows users) that you didn't specify the path to the ImageMagick binary in file conf.py, or that the path you specified is incorrect"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Option 2"
      ],
      "metadata": {
        "id": "41CGLLSsv1Pd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import random\n",
        "from moviepy.editor import VideoFileClip, TextClip\n",
        "from moviepy.video.tools.subtitles import SubtitlesClip\n",
        "\n",
        "# Load the video file\n",
        "video_clip = VideoFileClip(output_path)\n",
        "\n",
        "# Function to generate a random animation\n",
        "def random_animation(txt_clip, width, duration):\n",
        "    animation_list = [\n",
        "        txt_clip.set_position(('left', 'bottom')).set_duration(duration).margin(left=10, right=10, bottom=10),\n",
        "        txt_clip.set_position(('right', 'top')).set_duration(duration).margin(right=10, top=10),\n",
        "        txt_clip.set_position(('center', 'bottom')).set_duration(duration).margin(bottom=10),\n",
        "        txt_clip.set_position(('center', 'top')).set_duration(duration).margin(top=10),\n",
        "        txt_clip.set_position(('left', 'center')).set_duration(duration).margin(left=10),\n",
        "        txt_clip.set_position(('right', 'center')).set_duration(duration).margin(right=10)\n",
        "    ]\n",
        "    return random.choice(animation_list)\n",
        "\n",
        "# Create subtitle clips with animations\n",
        "subtitles = []\n",
        "start_time = 0\n",
        "for idea, duration in zip(ideas, line_percentage):\n",
        "    end_time = start_time + duration\n",
        "\n",
        "    # Create text clip with specified style\n",
        "    txt_clip = TextClip(idea, fontsize=24, color='#00D5F1', bg_color='black', size=video_clip.size)\n",
        "\n",
        "    # Apply a random animation to the text clip\n",
        "    animated_clip = random_animation(txt_clip, video_clip.w, duration)\n",
        "\n",
        "    subtitles.append(((start_time, end_time), animated_clip))\n",
        "    start_time = end_time\n",
        "\n",
        "# Create the subtitle composition\n",
        "subtitles_composition = SubtitlesClip(subtitles)\n",
        "\n",
        "# Overlay subtitles on the video\n",
        "video_with_subtitles = CompositeVideoClip([video_clip, subtitles_composition.set_duration(video_clip.duration)])\n",
        "\n",
        "# Export the final video\n",
        "video_with_subtitles.write_videofile(final_video, codec='libx264')\n"
      ],
      "metadata": {
        "id": "16-qXKXfnO6W",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 564
        },
        "outputId": "d92f012b-23d1-4399-8d6b-5a520736da31"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "error",
          "ename": "OSError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/moviepy/video/VideoClip.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, txt, filename, size, color, bg_color, fontsize, font, stroke_color, stroke_width, method, kerning, align, interline, tempfilename, temptxt, transparent, remove_temp, print_cmd)\u001b[0m\n\u001b[1;32m   1136\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1137\u001b[0;31m             \u001b[0msubprocess_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcmd\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogger\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1138\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mIOError\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mOSError\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/moviepy/tools.py\u001b[0m in \u001b[0;36msubprocess_call\u001b[0;34m(cmd, logger, errorprint)\u001b[0m\n\u001b[1;32m     45\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 46\u001b[0;31m     \u001b[0mproc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mPopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcmd\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mpopen_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     47\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.10/subprocess.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, args, bufsize, executable, stdin, stdout, stderr, preexec_fn, close_fds, shell, cwd, env, universal_newlines, startupinfo, creationflags, restore_signals, start_new_session, pass_fds, user, group, extra_groups, encoding, errors, text, umask, pipesize)\u001b[0m\n\u001b[1;32m    970\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 971\u001b[0;31m             self._execute_child(args, executable, preexec_fn, close_fds,\n\u001b[0m\u001b[1;32m    972\u001b[0m                                 \u001b[0mpass_fds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcwd\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0menv\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.10/subprocess.py\u001b[0m in \u001b[0;36m_execute_child\u001b[0;34m(self, args, executable, preexec_fn, close_fds, pass_fds, cwd, env, startupinfo, creationflags, shell, p2cread, p2cwrite, c2pread, c2pwrite, errread, errwrite, restore_signals, gid, gids, uid, umask, start_new_session)\u001b[0m\n\u001b[1;32m   1862\u001b[0m                         \u001b[0merr_msg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstrerror\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merrno_num\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1863\u001b[0;31m                     \u001b[0;32mraise\u001b[0m \u001b[0mchild_exception_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merrno_num\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merr_msg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merr_filename\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1864\u001b[0m                 \u001b[0;32mraise\u001b[0m \u001b[0mchild_exception_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merr_msg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'unset'",
            "\nDuring handling of the above exception, another exception occurred:\n",
            "\u001b[0;31mOSError\u001b[0m                                   Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-10-156620fae758>\u001b[0m in \u001b[0;36m<cell line: 23>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m     \u001b[0;31m# Create text clip with specified style\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 27\u001b[0;31m     \u001b[0mtxt_clip\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextClip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0midea\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfontsize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m24\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolor\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'#00D5F1'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbg_color\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'black'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvideo_clip\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     28\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m     \u001b[0;31m# Apply a random animation to the text clip\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/moviepy/video/VideoClip.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, txt, filename, size, color, bg_color, fontsize, font, stroke_color, stroke_width, method, kerning, align, interline, tempfilename, temptxt, transparent, remove_temp, print_cmd)\u001b[0m\n\u001b[1;32m   1144\u001b[0m                         \u001b[0;34m\"ImageMagick binary in file conf.py, or that the path \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1145\u001b[0m                         \"you specified is incorrect\"))\n\u001b[0;32m-> 1146\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mIOError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merror\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1147\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1148\u001b[0m         \u001b[0mImageClip\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtempfilename\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtransparent\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtransparent\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mOSError\u001b[0m: MoviePy Error: creation of None failed because of the following error:\n\n[Errno 2] No such file or directory: 'unset'.\n\n.This error can be due to the fact that ImageMagick is not installed on your computer, or (for Windows users) that you didn't specify the path to the ImageMagick binary in file conf.py, or that the path you specified is incorrect"
          ]
        }
      ]
    }
  ]
}